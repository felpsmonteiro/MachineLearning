{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d901349c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:21:46.999459Z",
     "start_time": "2022-05-12T23:21:46.723141Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, pi, sqrt, exp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587f6dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:21:47.014667Z",
     "start_time": "2022-05-12T23:21:47.000644Z"
    },
    "code_folding": [
     1,
     8,
     10,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def NormZscore(data):\n",
    "    mean = np.mean(data, axis = 0)\n",
    "    data_int = data - mean\n",
    "    sdt = np.std(data, axis = 0)\n",
    "    data_norm = data_int / sdt\n",
    "\n",
    "    return data_norm, mean, sdt\n",
    "def DesnZscore(data,m,s):\n",
    "    return data * s + m\n",
    "def kfolds(dataset, k):\n",
    "    shuf = np.random.permutation(dataset)\n",
    "    n = shuf.shape[0]\n",
    "    k = 10\n",
    "    fold_size = n // k\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k-1):\n",
    "        #print(i*fold_size, (i+1)*fold_size)\n",
    "        folds.append(shuf[i*fold_size:(i+1)*fold_size,:])\n",
    "\n",
    "    folds.append(shuf[(k-1)*fold_size:,:])\n",
    "\n",
    "    return folds\n",
    "def Sigm(x, w):\n",
    "    return 1 / (1 + np.exp(-x @ w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16c3b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:21:47.030796Z",
     "start_time": "2022-05-12T23:21:47.015677Z"
    },
    "code_folding": [
     0,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def fitLR(x, y, alpha=1, epoch=5):\n",
    "    onecolumn = np.ones(x.shape[0])\n",
    "    X = np.c_[onecolumn, x]\n",
    "    w_pred = np.zeros((X.shape[1], 1))\n",
    "\n",
    "    err_list = []\n",
    "    \n",
    "    for e in range (0, epoch):\n",
    "        error = y - Sigm(X, w_pred)\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            w_pred[i] += alpha * (np.mean(error * X[:,i]))\n",
    "        \n",
    "        err = np.mean(- y * np.log(Sigm(X, w_pred)) - (1 - y) * np.log(1 - Sigm(X, w_pred)))\n",
    "\n",
    "        err_list.append(err)\n",
    "    \n",
    "    return w_pred, err_list\n",
    "def predLR(X, w_pred):\n",
    "    onecolumn = np.ones(X.shape[0])\n",
    "    X = np.c_[onecolumn, X]\n",
    "    \n",
    "    Y = []\n",
    "    \n",
    "    for j in range(0, X.shape[0]):\n",
    "        y_pred = Sigm(X[i], w_pred)\n",
    "\n",
    "        if y_pred >= 0.5:\n",
    "            Y.append(1)\n",
    "\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e39b10",
   "metadata": {
    "code_folding": [
     1,
     38
    ]
   },
   "outputs": [],
   "source": [
    "#NaiveBayes\n",
    "def fitNB(x, y):\n",
    "    classes_nb, counts_nb = np.unique(y, return_counts=True)\n",
    "\n",
    "    nClasses_nb = len(classes_nb)\n",
    "\n",
    "    n_nb = y.shape[0]\n",
    "\n",
    "    nFeatures_nb = x.shape[1]\n",
    "\n",
    "    probClasses_nb = {classes_nb[i]: counts_nb[i] for i in range(len(counts_nb))}\n",
    "\n",
    "    for k_nb in probClasses_nb:\n",
    "            probClasses_nb[k_nb] = round(probClasses_nb[k_nb] / n_nb, 6)\n",
    "\n",
    "    mean_nb = np.zeros((nFeatures_nb, nClasses_nb))\n",
    "    covar_nb = np.zeros((nFeatures_nb, nClasses_nb))\n",
    "    x_c_nb = []\n",
    "\n",
    "    for c_nb in classes_nb:\n",
    "\n",
    "        x_i_nb = []\n",
    "\n",
    "        for i_nb in range(0, x.shape[0]):\n",
    "            if c_nb == y[i_nb]:\n",
    "                x_i_nb.append(x[i_nb])\n",
    "\n",
    "        x_c_nb.append(np.array(x_i_nb))\n",
    "\n",
    "    x_c_nb = np.array(x_c_nb, dtype=object)\n",
    "\n",
    "    for p_nb in range(classes_nb.shape[0]):\n",
    "        mean_nb[:, p_nb] = np.mean(x_c_nb[p_nb], axis=0)\n",
    "        x_mean_nb = x_c_nb[p_nb] - mean_nb[:, p_nb]\n",
    "\n",
    "        covar_nb[:,p_nb] = np.sum((x_mean_nb)**2, axis=0) / x_c_nb[p_nb].shape[0]\n",
    "    \n",
    "    return nClasses_nb, covar_nb, mean_nb, probClasses_nb, classes_nb\n",
    "def predNB(x, nClasses_nb, covar_nb, mean_nb, probClasses_nb, classes_nb):\n",
    "    prob_x_nb = np.zeros((x.shape[0], nClasses_nb))\n",
    "\n",
    "    for ix_nb in range(x.shape[0]):\n",
    "        for ic_nb in range(nClasses_nb):\n",
    "            fat1_nb = - 0.5 * np.sum(np.log(2*pi*covar_nb[:, ic_nb]))\n",
    "            fat2_nb = - 0.5 * np.sum((x[ix_nb, :] - mean_nb[:, ic_nb])**2 / covar_nb[:,ic_nb])\n",
    "            fat3_nb = np.log(probClasses_nb[ic_nb])\n",
    "\n",
    "            prob_x_nb[ix_nb, ic_nb] = fat1_nb + fat2_nb + fat3_nb\n",
    "\n",
    "    y_pred_nb = []\n",
    "\n",
    "    for i_nb in range(x.shape[0]):\n",
    "        y_pred_nb.append(classes_nb[np.argmax(prob_x_nb[i_nb, :])])\n",
    "\n",
    "    return y_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eea1c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:21:47.060698Z",
     "start_time": "2022-05-12T23:21:47.032721Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "bc = np.genfromtxt('./breastcancer.csv', delimiter=',')\n",
    "bcsize = bc.shape[0]\n",
    "\n",
    "x_norm, x_mean, x_sdt = NormZscore(bc[:,0:30])\n",
    "x_des = DesnZscore(x_norm, x_mean, x_sdt)\n",
    "y = bc[:,[30]]\n",
    "\n",
    "bc_norm = np.c_[x_norm, y]\n",
    "\n",
    "folds = kfolds(bc_norm, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73a596a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:37:18.561572Z",
     "start_time": "2022-05-12T23:37:18.546419Z"
    },
    "code_folding": [
     1,
     46
    ]
   },
   "outputs": [],
   "source": [
    "#ADG\n",
    "def fitADG(x, y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    nClasses = len(classes)\n",
    "\n",
    "    n = y.shape[0]\n",
    "\n",
    "    nFeatures = x.shape[1]\n",
    "\n",
    "    probClasses = {classes[i]: counts[i] for i in range(len(counts))}\n",
    "\n",
    "    for k in probClasses:\n",
    "            probClasses[k] = round(probClasses[k] / n, 6)\n",
    "\n",
    "    mean = np.zeros((nFeatures, nClasses))\n",
    "    covar = np.zeros((nFeatures, nFeatures, nClasses))\n",
    "    x_c = []\n",
    "\n",
    "    for c in classes:\n",
    "\n",
    "        x_i = []\n",
    "\n",
    "        for i in range(0, x.shape[0]):\n",
    "            if c == y[i]:\n",
    "                x_i.append(x[i])\n",
    "\n",
    "        x_c.append(np.array(x_i))\n",
    "\n",
    "    x_c = np.array(x_c, dtype=object)\n",
    "\n",
    "    for p in range(classes.shape[0]):\n",
    "        mean[:, p] = np.mean(x_c[p], axis=0)\n",
    "        x_mean = x_c[p] - mean[:, p]\n",
    "\n",
    "        covar[:,:,p] = (np.transpose(x_mean) @ x_mean) / counts[p]\n",
    "\n",
    "    det = np.zeros(nClasses)    \n",
    "    inv = np.zeros((nFeatures, nFeatures, nClasses))\n",
    "\n",
    "    for cl in range (nClasses):\n",
    "        det[cl] = np.linalg.det(covar[:, :, cl])\n",
    "\n",
    "        inv[:, :, cl] = (np.linalg.inv(covar[:, :, cl]))\n",
    "\n",
    "    return mean, inv, det, nClasses, probClasses, nFeatures, classes\n",
    "def predADG(x, mean, inv, det, nClasses, probClasses, nFeatures, classes):\n",
    "    prob_x = np.zeros((x.shape[0], nClasses))\n",
    "    \n",
    "    for ix in range(x.shape[0]):\n",
    "        for ic in range(nClasses):\n",
    "            fat1 = (1/ (sqrt(det[ic]) * ((2*pi)**(nFeatures/2))))\n",
    "            fat2 = np.exp(-(0.5) * np.transpose(x[ix] - mean[:, ic]) @ inv[:, :, ic] @ (x[ix] - mean[:, ic]))\n",
    "            fat3 = np.log(probClasses[ic])\n",
    "            prob_x[ix, ic] = fat1 * fat2 * fat3\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        y_pred.append(classes[np.argmax(prob_x[i, :])])\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61edef0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:37:22.610632Z",
     "start_time": "2022-05-12T23:37:20.729034Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traintest = []\n",
    "modelsLR = []\n",
    "modelsADG = []\n",
    "modelsNB = []\n",
    "predsLR = []\n",
    "predsADG = []\n",
    "predsNB = []\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    test = folds[i]\n",
    "    train = []\n",
    "    for f in range(len(folds)):\n",
    "        if i != f:\n",
    "            train.extend(folds[f])\n",
    "    \n",
    "    #traintest.append((train, test))\n",
    "\n",
    "    x_train = np.array(train)[:,0:30]\n",
    "    y_train = np.array(train)[:,30]\n",
    "    \n",
    "    x_test = np.array(test)[:,0:30]\n",
    "    y_test = np.array(test)[:,30]\n",
    "    \n",
    "    traintest.append((x_train, y_train, x_test, y_test))\n",
    "    \n",
    "    modelsLR.append(fitLR(x_train, y_train))\n",
    "    modelsADG.append(fitADG(x_train, y_train))\n",
    "    modelsNB.append(fitNB(x_train, y_train))\n",
    "    \n",
    "for i in range(len(folds)):\n",
    "    x_train, y_train, x_test, y_test  = traintest[i]\n",
    "\n",
    "    predsLR.append(predLR(x_test, modelsLR[i][0]))\n",
    "    predsADG.append(predADG(x_test, modelsADG[i][0], modelsADG[i][1], modelsADG[i][2], modelsADG[i][3], modelsADG[i][4], modelsADG[i][5], modelsADG[i][6]))\n",
    "    predsNB.append(predNB(x_test, modelsNB[i][0], modelsNB[i][1], modelsNB[i][2], modelsNB[i][3], modelsNB[i][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e22368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:37:26.448563Z",
     "start_time": "2022-05-12T23:37:26.431260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsADG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052c2792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T23:21:48.652036Z",
     "start_time": "2022-05-12T23:21:48.637091Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc(y, y_pred):\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]:\n",
    "            TP += 1\n",
    "    return TP / float(len(y)) * 100.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
